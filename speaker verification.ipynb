{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7uGwZJoeQxGk"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import combinations, product\n",
    "import pickle\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ],
   "metadata": {
    "id": "VcQPWG_XjAXT"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "RfKfsal1Q6_2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "with open('hw4_trs.pkl', 'rb') as pickle_file:\n",
    "    train_data = pickle.load(pickle_file)\n",
    "print(train_data.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "id-2xNPRREck",
    "outputId": "d622002c-cba2-4e3b-9a3f-34a24b574a2d"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(500, 16180)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "with open('hw4_tes.pkl', 'rb') as pickle_file:\n",
    "    test_data = pickle.load(pickle_file)\n",
    "print(test_data.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afBfv5i-RfmI",
    "outputId": "fa4a4a92-3bc2-4abf-b8f9-d7dd83cfa3c8"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(200, 22631)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = np.stack([np.abs(librosa.stft(x, n_fft=1024, hop_length=512).T) for x in train_data])\n",
    "test_data = np.stack([np.abs(librosa.stft(x, n_fft=1024, hop_length=512).T) for x in test_data])"
   ],
   "metadata": {
    "id": "0Gw8jYuwRjxY"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_pos_pairs(spk_indices, L=45):\n",
    "    pos_pairs = list(combinations(spk_indices, 2))\n",
    "    return pos_pairs"
   ],
   "metadata": {
    "id": "6bkefycYRljY"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_neg_pairs(spk_indices, other_indices, L=45):\n",
    "    neg_pairs = list(product(spk_indices, other_indices))\n",
    "    l_pairs = random.sample(neg_pairs, L)\n",
    "    return l_pairs"
   ],
   "metadata": {
    "id": "OIfgF4qPRnlo"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_batches(data):\n",
    "    total_utterances = data.shape[0]\n",
    "    all_indices = list(range(total_utterances))\n",
    "    \n",
    "    left_input = []\n",
    "    right_input = []\n",
    "    output = []\n",
    "    \n",
    "    for i in range(0, total_utterances, 10):\n",
    "        speaker_indices = list(range(i, i+10))\n",
    "        pos_pairs = create_pos_pairs(speaker_indices)\n",
    "        other_indices = np.delete(all_indices, speaker_indices)\n",
    "        neg_pairs = create_neg_pairs(speaker_indices, other_indices)\n",
    "        \n",
    "        l_batch = []\n",
    "        r_batch = []\n",
    "        o_batch = []\n",
    "\n",
    "        for x, y in pos_pairs:\n",
    "            l_batch.append(data[x])\n",
    "            r_batch.append(data[y])\n",
    "            o_batch.append(1)\n",
    "\n",
    "        for x, y in neg_pairs:\n",
    "            l_batch.append(data[x])\n",
    "            r_batch.append(data[y])\n",
    "            o_batch.append(0)\n",
    "        \n",
    "        left_input.append(l_batch)\n",
    "        right_input.append(r_batch)\n",
    "        output.append(o_batch)\n",
    "    \n",
    "    return np.stack(left_input), np.stack(right_input), np.stack(output)"
   ],
   "metadata": {
    "id": "jjeQYGmYRpSn"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "left_train, right_train, y_train = generate_batches(train_data)\n",
    "left_test, right_test, y_test = generate_batches(test_data)"
   ],
   "metadata": {
    "id": "E0GX4RWMRrkG"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(left_train.shape, left_train.dtype)\n",
    "print(right_train.shape, right_train.dtype)\n",
    "print(y_train.shape,y_train.dtype)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bxVhcl5dRrpD",
    "outputId": "be2c908f-8925-42e5-8ebe-ca65dfe6d806"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50, 90, 32, 513) float32\n",
      "(50, 90, 32, 513) float32\n",
      "(50, 90) int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    " y_train = y_train.astype(np.float32)\n",
    " y_test = y_test.astype(np.float32)\n",
    " print(y_train.dtype)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2H2EoQzRrrr",
    "outputId": "a730f2fc-1de9-4748-c1d5-44e274695646"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "float32\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def create_placeholders():\n",
    "  left_x = tf.compat.v1.placeholder(tf.float32,shape = [None,None,513])\n",
    "  right_x = tf.compat.v1.placeholder(tf.float32,shape = [None,None,513])\n",
    "  y = tf.compat.v1.placeholder(tf.float32,shape = [None])\n",
    "  rows = tf.compat.v1.placeholder(tf.int32)\n",
    "\n",
    "  return left_x, right_x, y, rows"
   ],
   "metadata": {
    "id": "_SVi8oKsRruS"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def siamese_model(inputs, reuse, rows, num_units = [513]):\n",
    "  cells = [tf.nn.rnn_cell.BasicLSTMCell(num_units=n, reuse = reuse) for n in num_units]\n",
    "  stacked_lstm = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "  rnn_op, state = tf.nn.dynamic_rnn(stacked_lstm, inputs, dtype = tf.float32)\n",
    "  dense_1 = tf.layers.dense(rnn_op, 513, activation=tf.nn.tanh, reuse = reuse)\n",
    "  output = tf.reshape(dense_1,shape = [-1, rows*513])\n",
    "  return output"
   ],
   "metadata": {
    "id": "MLPoJIOFRrwn"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def model(train_data, test_data, learning_rate = 0.0005, num_epochs = 100):\n",
    "  tf.compat.v1.reset_default_graph()\n",
    "\n",
    "  x1, x2, y, rows  = create_placeholders()\n",
    "  left_train, right_train, y_train = train_data\n",
    "  left_test, right_test, y_test = test_data\n",
    "\n",
    "  left_op = siamese_model(x1,False,rows)\n",
    "  right_op = siamese_model(x2,True,rows)\n",
    "  dot_prod = tf.reduce_sum(tf.multiply(left_op,right_op),axis = 1)\n",
    "  yPred = tf.nn.sigmoid(dot_prod)\n",
    "\n",
    "  binary_op = tf.cast(tf.math.greater(yPred,0.5), tf.int16)\n",
    "  \n",
    "  cost = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = dot_prod))\n",
    "  \n",
    "  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "  init = tf.global_variables_initializer()\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        i = 0\n",
    "        for left, right, y_batch in zip(left_train,right_train,y_train):\n",
    "          row = left.shape[1]\n",
    "\n",
    "          _, batch_loss = sess.run([optimizer, cost], feed_dict ={x1: left, x2: right, y:y_batch, rows:row })  \n",
    "          epoch_loss += batch_loss\n",
    "          i += 1\n",
    "        test_accuracy = 0.0\n",
    "        j = 0\n",
    "        for left,right,y_batch in zip(left_test,right_test,y_test):\n",
    "            row = left.shape[1]\n",
    "            y_pred = sess.run(binary_op, feed_dict ={x1: left, x2: right, y:y_batch, rows: row})\n",
    "            test_accuracy += sum(y_pred == y_batch)\n",
    "            j+=1\n",
    "        print(epoch,\"Cost:\", epoch_loss/i, \" Test Accuracy: \", test_accuracy/j)\n",
    "\n",
    "    test_accuracy = 0.0\n",
    "    j = 0\n",
    "    for left,right,y_batch in zip(left_test,right_test,y_test):\n",
    "      row = left.shape[1]\n",
    "      y_pred = sess.run(binary_op, feed_dict ={x1: left, x2: right, y:y_batch, rows: row})\n",
    "      test_accuracy += sum(y_pred == y_batch)\n",
    "      j+=1\n",
    "    \n",
    "    print(\"Final Test Accuracy: \", test_accuracy/j)\n",
    "    return test_accuracy/j"
   ],
   "metadata": {
    "id": "z2oJ2yCFRryp"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tr_data = [left_train, right_train, y_train.astype(float)]\n",
    "te_data = [left_test, right_test, y_test]\n",
    "acc = model(tr_data, te_data)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzlF9AHYRr1E",
    "outputId": "fb595e55-b1da-4a1c-d484-e2981fc436ea"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  \n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-19-e5f1b4f7a1ff>:4: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/rnn/legacy_cells.py:726: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  \"\"\"\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 Cost: 535.3697467041015  Test Accuracy:  59.85\n",
      "1 Cost: 61.108204956054685  Test Accuracy:  61.85\n",
      "2 Cost: 49.69364757537842  Test Accuracy:  62.45\n",
      "3 Cost: 44.704769439697266  Test Accuracy:  63.0\n",
      "4 Cost: 41.00812160491943  Test Accuracy:  63.25\n",
      "5 Cost: 37.50990997314453  Test Accuracy:  62.95\n",
      "6 Cost: 33.98905679702759  Test Accuracy:  62.15\n",
      "7 Cost: 30.228298244476317  Test Accuracy:  61.3\n",
      "8 Cost: 26.110195770263672  Test Accuracy:  60.8\n",
      "9 Cost: 21.685269117355347  Test Accuracy:  60.55\n",
      "10 Cost: 17.081714115142823  Test Accuracy:  60.8\n",
      "11 Cost: 12.614518013000488  Test Accuracy:  60.45\n",
      "12 Cost: 9.378938064575195  Test Accuracy:  59.2\n",
      "13 Cost: 7.919217329025269  Test Accuracy:  59.65\n",
      "14 Cost: 10.907085089683532  Test Accuracy:  54.4\n",
      "15 Cost: 19.522409992218016  Test Accuracy:  57.5\n",
      "16 Cost: 18.447907762527464  Test Accuracy:  59.35\n",
      "17 Cost: 9.589840559959411  Test Accuracy:  58.95\n",
      "18 Cost: 4.611269690990448  Test Accuracy:  58.45\n",
      "19 Cost: 2.455052822828293  Test Accuracy:  58.35\n",
      "20 Cost: 1.4713366378843784  Test Accuracy:  60.9\n",
      "21 Cost: 0.9987780868262053  Test Accuracy:  61.65\n",
      "22 Cost: 0.4000053272396326  Test Accuracy:  61.6\n",
      "23 Cost: 0.34327845682390035  Test Accuracy:  62.0\n",
      "24 Cost: 0.16280731370672583  Test Accuracy:  63.05\n",
      "25 Cost: 0.11251902393531055  Test Accuracy:  62.95\n",
      "26 Cost: 0.0821822965145111  Test Accuracy:  62.85\n",
      "27 Cost: 0.06811528254766017  Test Accuracy:  62.9\n",
      "28 Cost: 0.05815966074354947  Test Accuracy:  62.95\n",
      "29 Cost: 0.05049988226033747  Test Accuracy:  63.0\n",
      "30 Cost: 0.04441131565719843  Test Accuracy:  63.15\n",
      "31 Cost: 0.03944862233940512  Test Accuracy:  63.15\n",
      "32 Cost: 0.03532623606733978  Test Accuracy:  63.15\n",
      "33 Cost: 0.03185006809886545  Test Accuracy:  63.15\n",
      "34 Cost: 0.028882475565187634  Test Accuracy:  63.2\n",
      "35 Cost: 0.02632268939167261  Test Accuracy:  63.15\n",
      "36 Cost: 0.024095020932145418  Test Accuracy:  63.15\n",
      "37 Cost: 0.022141407483723015  Test Accuracy:  63.2\n",
      "38 Cost: 0.020416535784024744  Test Accuracy:  63.3\n",
      "39 Cost: 0.018884461894631385  Test Accuracy:  63.3\n",
      "40 Cost: 0.017516327360644936  Test Accuracy:  63.3\n",
      "41 Cost: 0.01628869171254337  Test Accuracy:  63.35\n",
      "42 Cost: 0.01518230513902381  Test Accuracy:  63.35\n",
      "43 Cost: 0.014181217961013317  Test Accuracy:  63.25\n",
      "44 Cost: 0.013272112372796983  Test Accuracy:  63.25\n",
      "45 Cost: 0.01244376961607486  Test Accuracy:  63.25\n",
      "46 Cost: 0.011686677213292569  Test Accuracy:  63.25\n",
      "47 Cost: 0.010992735556792468  Test Accuracy:  63.25\n",
      "48 Cost: 0.01035499274963513  Test Accuracy:  63.25\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ThsFqcDoRr20"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}